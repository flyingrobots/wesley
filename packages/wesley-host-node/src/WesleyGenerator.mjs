/**
 * Wesley Main Generator - Orchestrates all generators and emits evidence bundle
 */

import { writeFileSync, mkdirSync, existsSync, readFileSync } from 'node:fs';
import { dirname, join } from 'node:path';
import { execSync } from 'node:child_process';
import { 
  EvidenceMap, 
  ScoringEngine,
  DirectiveProcessor 
} from '@wesley/core';
import { GraphQLSchemaParser } from './parsers/GraphQLSchemaParser.mjs';
import { PostgreSQLGenerator } from './generators/PostgreSQLGenerator.mjs';
import { MigrationDiffEngine, MigrationSQLGenerator } from './generators/MigrationDiffEngine.mjs';
import { PgTAPTestGenerator } from './generators/PgTAPTestGenerator.mjs';

export class WesleyGenerator {
  constructor(options = {}) {
    this.outputDir = options.outputDir || 'out';
    this.wesleyDir = options.wesleyDir || '.wesley';
    this.migrationsDir = options.migrationsDir || 'db/migrations';
    this.testsDir = options.testsDir || 'tests';
  }

  /**
   * Main generation pipeline
   */
  async generate(schemaPath, options = {}) {
    console.log('ðŸš€ Wesley: Starting generation pipeline...');
    
    // Ensure directories exist
    this.ensureDirectories();
    
    // Get current commit SHA
    const sha = this.getCurrentSHA();
    
    // Initialize evidence map
    const evidenceMap = new EvidenceMap();
    evidenceMap.setSha(sha);
    
    // 1. Parse GraphQL schema
    console.log('ðŸ“– Parsing GraphQL schema...');
    const sdl = readFileSync(schemaPath, 'utf8');
    const parser = new GraphQLSchemaParser();
    const schema = await parser.parse(sdl);
    
    // 2. Generate SQL
    console.log('ðŸ”¨ Generating SQL...');
    const sqlGenerator = new PostgreSQLGenerator(evidenceMap);
    const sql = await sqlGenerator.generate(schema);
    writeFileSync(join(this.outputDir, 'schema.sql'), sql);
    
    // 3. Generate migrations
    console.log('ðŸ”„ Calculating migrations...');
    const previousSchema = this.loadPreviousSchema();
    const migrationSteps = await this.generateMigrations(
      previousSchema, 
      schema, 
      evidenceMap
    );
    
    // 4. Generate tests
    console.log('ðŸ§ª Generating tests...');
    const testGenerator = new PgTAPTestGenerator(evidenceMap);
    const tests = await testGenerator.generate(schema, { 
      migrationSteps,
      supabase: options.supabase 
    });
    writeFileSync(join(this.testsDir, 'generated.sql'), tests);
    
    // 5. Calculate scores
    console.log('ðŸ“Š Calculating scores...');
    const scoringEngine = new ScoringEngine(evidenceMap);
    const scores = scoringEngine.exportScores(schema, migrationSteps, {
      total: 100, // Would be actual test results
      passed: 85
    });
    
    // 6. Save evidence bundle
    console.log('ðŸ’¾ Saving evidence bundle...');
    this.saveEvidenceBundle({
      schema,
      evidenceMap,
      scores,
      sha,
      timestamp: new Date().toISOString()
    });
    
    // 7. Update history
    this.updateHistory(scores);
    
    console.log('âœ… Wesley: Generation complete!');
    console.log(`   SCS: ${(scores.scores.scs * 100).toFixed(1)}%`);
    console.log(`   MRI: ${(scores.scores.mri * 100).toFixed(1)}%`);
    console.log(`   TCI: ${(scores.scores.tci * 100).toFixed(1)}%`);
    console.log(`   Verdict: ${scores.readiness.verdict}`);
    
    return {
      schema,
      evidenceMap,
      scores,
      files: {
        sql: join(this.outputDir, 'schema.sql'),
        tests: join(this.testsDir, 'generated.sql'),
        bundle: join(this.wesleyDir, 'bundle.json')
      }
    };
  }

  /**
   * Generate migrations
   */
  async generateMigrations(previousSchema, currentSchema, evidenceMap) {
    const diffEngine = new MigrationDiffEngine();
    const diff = await diffEngine.diff(previousSchema, currentSchema);
    
    if (diff.steps.length > 0) {
      const migrationGen = new MigrationSQLGenerator();
      const migrationSQL = await migrationGen.generate(diff);
      
      const timestamp = new Date().toISOString().replace(/[-:T.Z]/g, '').slice(0, 14);
      const migrationFile = join(this.migrationsDir, `${timestamp}_auto.sql`);
      
      writeFileSync(migrationFile, migrationSQL);
      console.log(`   Created migration: ${migrationFile}`);
      
      // Record migration in evidence map
      if (evidenceMap) {
        evidenceMap.record('migration:latest', 'sql', {
          file: migrationFile,
          lines: '1-*',
          sha: evidenceMap.sha
        });
      }
    }
    
    return diff.steps;
  }

  /**
   * Save the evidence bundle
   */
  saveEvidenceBundle(data) {
    const { schema, evidenceMap, scores, sha, timestamp } = data;
    
    // Save IR
    writeFileSync(
      join(this.wesleyDir, 'schema.ir.json'),
      JSON.stringify(schema.toJSON(), null, 2)
    );
    
    // Save evidence map
    writeFileSync(
      join(this.wesleyDir, 'evidence-map.json'),
      JSON.stringify(evidenceMap.toJSON(), null, 2)
    );
    
    // Save scores
    writeFileSync(
      join(this.wesleyDir, 'scores.json'),
      JSON.stringify(scores, null, 2)
    );
    
    // Save complete bundle
    const bundle = {
      sha,
      timestamp,
      schema: schema.toJSON(),
      evidence: evidenceMap.toJSON(),
      scores
    };
    
    writeFileSync(
      join(this.wesleyDir, 'bundle.json'),
      JSON.stringify(bundle, null, 2)
    );
    
    // Save as snapshot for next diff
    writeFileSync(
      join(this.wesleyDir, 'snapshot.json'),
      JSON.stringify(schema.toJSON(), null, 2)
    );
  }

  /**
   * Update history for predictions
   */
  updateHistory(scores) {
    const historyPath = join(this.wesleyDir, 'history.json');
    let history = { points: [] };
    
    if (existsSync(historyPath)) {
      history = JSON.parse(readFileSync(historyPath, 'utf8'));
    }
    
    history.points.push({
      timestamp: new Date().toISOString(),
      sha: scores.commit,
      scs: scores.scores.scs,
      mri: scores.scores.mri,
      tci: scores.scores.tci,
      day: Math.floor(Date.now() / (1000 * 60 * 60 * 24))
    });
    
    // Keep last 60 points
    if (history.points.length > 60) {
      history.points = history.points.slice(-60);
    }
    
    writeFileSync(historyPath, JSON.stringify(history, null, 2));
  }

  /**
   * Load previous schema for diffing
   */
  loadPreviousSchema() {
    const snapshotPath = join(this.wesleyDir, 'snapshot.json');
    
    if (existsSync(snapshotPath)) {
      return JSON.parse(readFileSync(snapshotPath, 'utf8'));
    }
    
    return { tables: {} };
  }

  /**
   * Get current git SHA
   */
  getCurrentSHA() {
    try {
      return execSync('git rev-parse HEAD', { encoding: 'utf8' }).trim();
    } catch {
      return 'uncommitted';
    }
  }

  /**
   * Ensure all directories exist
   */
  ensureDirectories() {
    const dirs = [
      this.outputDir,
      this.wesleyDir,
      this.migrationsDir,
      this.testsDir
    ];
    
    for (const dir of dirs) {
      if (!existsSync(dir)) {
        mkdirSync(dir, { recursive: true });
      }
    }
  }
}